# Distributed-Caching-System
A scalable Distributed Caching System using Redis, Featuring Replication, Sharding, and Monitoring for high availability and fault tolerance.

A cache is a high-speed storage layer that stores a subset of data, typically in-memory, so that future requests for that data are faster 
compared to fetching it from a slower source (like a database or a disk).

A distributed cache takes this concept a step further by distributing the cache across multiple nodes (servers or instances) in a network. 
This enables handling larger datasets and increasing system reliability and scalability by distributing the load.
